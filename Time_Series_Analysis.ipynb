{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJanbandhu/DeepLearning/blob/main/Time_Series_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHChvaQjPvJ0"
      },
      "source": [
        "# what is Timeseries?\n",
        "* Time Series algorithm provides multiple algorithms that are optimized for forecasting continuous values, such as product sales, over time.A time series model can predict trends based only on the original dataset that is used to create the model.\n",
        "* Across industries, organizations commonly use time series data, which means any information collected over a regular interval of time, in their operations. Examples include daily stock prices, energy consumption rates, social media engagement metrics and retail demand, among others. Analyze time series data yields insights like trends, seasonal patterns and forecasts into future events that can help generate profits. For example, by understanding the seasonal trends in demand for retail products, companies can plan promotions to maximize sales throughout the year.\n",
        "\n",
        "**White noise**\n",
        "* A time series is white noise if the variables are independent and identically distributed with a mean of zero. This means that all variables have the same variance (sigma^2) and each value has a zero correlation with all other values in the series.\n",
        "\n",
        "\n",
        "**Data patterns**\n",
        "\n",
        "**cycle**\n",
        "* A cyclic pattern occurs when data rise and fall, but this does not happen within the fixed time and the duration of these fluctuations is usually at least 2 years\n",
        "![](cycle.png)\n",
        "\n",
        "**Trend**\n",
        "* A trend pattern exists when there is a long-term increase or decrease in the series. The trend can be linear, exponential\n",
        "![](trend.png)\n",
        "\n",
        "**Seasonal**\n",
        "* Seasonality exists when data is influenced by seasonal factors, such as a day of the week, a month, and one-quarter of the     year. A seasonal pattern exists of a fixed known period.\n",
        "![](sea.png)\n",
        "\n",
        "**Random**\n",
        "* which do not follow any trend ,cycle or seasonal patterns\n",
        "![](ran.png)\n",
        "\n",
        "\n",
        "**Types**\n",
        "* Types of time series models are moving average,ARIMA.The crucial thing is to choose the right forecasting method as per the characteristics of the time series data.\n",
        "\n",
        "\n",
        "\n",
        "**MA(Moving Average)**\n",
        "* A moving average is defined as an average of fixed number of items in the time series which move through the series by dropping the top items of the previous averaged group and adding the next in each successive average.\n",
        "Yt depends only on random error terms\n",
        "     \tYt = f( εt, εt-1, εt-2, εt-3, ..)\n",
        "\t\tor\n",
        " \tYt = β + εt + θ1 εt-1 + θ2εt-2 + θ3 εt-3 +…\n",
        "\n",
        "\n",
        "\n",
        "**AR(Auto Regressive)**\n",
        "* Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. It is a very simple idea that can result in accurate forecasts on a range of time series problems.\n",
        "* Yt depends only of past values.\n",
        "* Yt-1, Yt-2, Yt-3 etc\n",
        "              * Yt  = f(Yt-1, Yt-2, Yt-3… )\n",
        "              * Yt = β0 + β1Yt-1 + β2Yt-2 + β3Yt-3 …\n",
        "\n",
        "\n",
        "**ARMA**\n",
        "* Time series, autoregressive–moving-average (ARMA) models provide a parsimonious description of a (weakly) stationary stochastic process in terms of two polynomials, one for the autoregression (AR) and the second for the moving average (MA).\n",
        "* Combines AR and MA\n",
        "\t* Yt = β0 + β1Yt-1 + β2Yt-2 + β3Yt-3 …εt + θ1 εt-1 + θ2εt-2 + θ3 εt-3 +…\n",
        "\n",
        "\n",
        "**ARIMA**\n",
        "* Autoregressive Integrated Moving Average (ARIMA) model is another widely used forecasting technique that involves the combination of two or more time series models. This model is suitable for multivariate non-stationary data. ARIMA method is based on the concepts of autoregression, autocorrelation, and moving average.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0yNrXmpGcKE"
      },
      "source": [
        "### Create a Time Series Model to predict the future passengers number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UO9RWLyWPvKb"
      },
      "outputs": [],
      "source": [
        "## Importing libraies\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ls0X4OWlPvKe"
      },
      "outputs": [],
      "source": [
        "## loading the data\n",
        "data=pd.read_csv('AirPassengers.csv')\n",
        "# we have data of airline passengers travelled between January 1949 and December 1960"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNs3ffeyPvKh"
      },
      "outputs": [],
      "source": [
        "data.head()#first two rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j30sCuJRPvKn"
      },
      "outputs": [],
      "source": [
        "data.info()#info about datatype and null value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7d7CZG-GcKT"
      },
      "outputs": [],
      "source": [
        "# Month is actually given as string here. It must be in date-time format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1xsw6ahPvKs"
      },
      "outputs": [],
      "source": [
        "## parse_dates: parsing the date (Converts the string representation of a date to Date object)\n",
        "# index_col: using date column as index\n",
        "\n",
        "data=pd.read_csv('AirPassengers.csv',parse_dates=[0],index_col='Month')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jai9mIByPvK0"
      },
      "source": [
        "# Basic checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHukVkFPPvK5"
      },
      "outputs": [],
      "source": [
        "data.head()#first five rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vwHH9GfGcKb"
      },
      "outputs": [],
      "source": [
        "data.rename(columns = {'#Passengers': 'Passengers'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGhC9BupGcKd"
      },
      "outputs": [],
      "source": [
        "data['Passengers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt5nqjUWPvLB"
      },
      "outputs": [],
      "source": [
        "data.tail()#last five rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBS9mnCxPvLF",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "data.describe() ##used to view some basic statistical details like percentile, mean, std etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n41q_JFPvLH"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cKfSV7yPvLJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10),facecolor='white')#canvas  size\n",
        "plt.plot(data)#line plot\n",
        "plt.tight_layout()\n",
        "## from plot we can see the series given is not stationary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z21N8nnFPvLM"
      },
      "source": [
        "## Stationarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWPlYwNnPvLN"
      },
      "source": [
        "* Stationarity means that the statistical properties of a time series (or rather the process generating it) do not change over time.\n",
        "* Stationarity is important because many useful analytical tools and statistical tests and models rely on it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFpHTq9tPvLO"
      },
      "source": [
        "* Constant mean\n",
        "* Constant variance\n",
        "* Constant covariance between periods of identical distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaKG7T53PvLQ"
      },
      "source": [
        "* All it states is that the covariance between time periods of identical lengths (let’s say 10 days/hours/minutes) should be identical to the covariance of some other period of the same length:\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6nUJAojPvLR"
      },
      "source": [
        "**why do we need stationarity?**\n",
        "- Stationary processes are easier to analyze\n",
        "- Stationarity is assumed by most of the algorithms\n",
        "- It is essential to remove any trend or seasonality before modeling the time series data because if the statistical properties do not change over time, it is easier to model the data accurately. One of the popular ways of making the series stationary is differencing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zudgz6HPvLY"
      },
      "source": [
        "* How to check if given series is stationary or not.\n",
        "We need to check autocorrelation\n",
        "Autocorrelation is the similarity between observations as a function of the time lag between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tm6yxI3PvLa"
      },
      "source": [
        "* When plotting the value of the ACF for increasing lags (a plot called a correlogram), the values tend to degrade to zero quickly for stationary time series (see figure 1, right), while for non-stationary data the degradation will happen more slowly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LVkB1ELPvLb"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from statsmodels.graphics.tsaplots import plot_acf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqNUV5uZPvLe"
      },
      "outputs": [],
      "source": [
        "plot_acf(data);\n",
        "## from the autocorrelation plot it is clear that given series is not stationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjoWZte_PvLi"
      },
      "outputs": [],
      "source": [
        "## making it stationary by taking difference of 1\n",
        "data1=data.diff(periods=1)\n",
        "\n",
        "\n",
        "#diff() will subtract 1 cell value from another cell value within the same index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN2HiWjDPvLk"
      },
      "outputs": [],
      "source": [
        "#loading the data\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeJx92rCPvLl"
      },
      "outputs": [],
      "source": [
        "#Remove the 1st row\n",
        "data1=data1.iloc[1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjE9ANvkPvLm"
      },
      "outputs": [],
      "source": [
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XlNQ3DBPvLo"
      },
      "outputs": [],
      "source": [
        "#A plot of the autocorrelation of a time series by lag\n",
        "plot_acf(data1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q9T0ojqGcKv"
      },
      "outputs": [],
      "source": [
        "data2=data1.diff(periods=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq4zQDGZGcKx"
      },
      "outputs": [],
      "source": [
        "data3=data2.iloc[1:] # remove 1st record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk1lSwdeGcKy"
      },
      "outputs": [],
      "source": [
        "#A plot of the autocorrelation of a time series by lag\n",
        "plot_acf(data3);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POLYbYWrGcKz"
      },
      "outputs": [],
      "source": [
        "data3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIPKkmWuPvLu"
      },
      "outputs": [],
      "source": [
        "## Creating training and test sets\n",
        "train=data3[:100] #from 0th to 99th record - traning data\n",
        "test=data3[100:] #from 100th record to end - testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a9dXKhgGcK1"
      },
      "outputs": [],
      "source": [
        "# We cannot use train_test_split as it will randomly take the records for both the set.\n",
        "# But in time series, we take records in the given order only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GL3_ryBwPvLv"
      },
      "outputs": [],
      "source": [
        "train.shape#info about datatype and null value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghGBipjFGcK3"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AWdcKYzijG1"
      },
      "outputs": [],
      "source": [
        "#pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HWUcZt6PvLx"
      },
      "outputs": [],
      "source": [
        "## Applying autoregressive model"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "SFWhOWEIGcK7"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "ar_model = AR(train)\n",
        "ar_m = ar_model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzjGOL21GcK8"
      },
      "outputs": [],
      "source": [
        "!pip install statsmodels==0.11.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZF7_6sMGcK-"
      },
      "outputs": [],
      "source": [
        "#ar_select_order : gives the best lags ordered as an array\n",
        "\n",
        "# to select the optimal lags\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statsmodels.tsa.ar_model import ar_select_order\n",
        "mod = ar_select_order(data1,maxlag=13,glob=True)\n",
        "mod.ar_lags\n",
        "\n",
        "# select_order: selects the best number of lags\n",
        "# maxlag: The maximum lag to consider\n",
        "# glob: global search across all combinations of lags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXeqUPxiGcLA"
      },
      "outputs": [],
      "source": [
        "# global search considers all lag combinations that include any lag between 1 and 15, but not\n",
        "# necessarily all contiguous lags, then the best combination of lags here is 1, 8, 12 and 13."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P_F5QO7GcLD"
      },
      "outputs": [],
      "source": [
        "#pip install pandas==1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CZaZKN0GcLF"
      },
      "outputs": [],
      "source": [
        "# Model creation\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "ar_mod = AutoReg(train,lags=[1,8,12,13]) # which lagged values has to be taken\n",
        "ar_m1 = ar_mod.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug5zOegOGcLH"
      },
      "outputs": [],
      "source": [
        "prediction=ar_m1.predict(start=100,end=142)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJbZDXgFGcLI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(test)\n",
        "plt.plot(prediction,color='green')#graph of test vs prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUAIFS4XPvL2"
      },
      "source": [
        "## ARIMA Model\n",
        "\n",
        "ARIMA consists of an integrated moving average of autoregressive time series.  ARIMA model is useful in the cases where the time series is non-stationary. And the differencing is required to make the time series stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMW2rm7qGcLK"
      },
      "outputs": [],
      "source": [
        "# No need to do differencing as ARIMA does it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecH-MJp4GcLN"
      },
      "outputs": [],
      "source": [
        "train=data[:100] #from 0th to 99th record - traning data\n",
        "test=data[100:] #from 100th record to end - testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6grnmWvDPvL3"
      },
      "outputs": [],
      "source": [
        "## importing the library\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "#from statsmodels.tsa.arima_model import ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQw4qA9WPvL4"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "##Model object creation and fitting the model\n",
        "model_arima = ARIMA(train, order=(2,1,2))#order= p,d,q (Randomly giving values for p,d,q)\n",
        "\n",
        "#p - autoregressive model\n",
        "#d - integrated order (no. of differencing done)\n",
        "#q - moving average model\n",
        "\n",
        "model_arima_fit = model_arima.fit()#training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVcXWdFuGcLP"
      },
      "source": [
        "Akaike Information Criteria (AIC):\n",
        "\n",
        "AIC is an estimator of prediction error which measures a statistical model in order to quantify the goodness of fit of the model. While comparing two models, the smaller the AIC value, the better the time series model.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "K: The number of model parameters.\n",
        "ln(L): The log-likelihood of the model. This tells us how likely the model is for the given data.\n",
        "\n",
        "\n",
        "AIC uses a model’s maximum likelihood estimation (log-likelihood) as a measure of fit. Log-likelihood is a measure of how likely one is to see their observed data, given a model. The model with the maximum likelihood is the one that “fits” the data the best. The natural log of the likelihood is used as a computational convenience.\n",
        "\n",
        "AIC is low for models with high log-likelihoods. This means the model fits the data better, which is what we want.\n",
        "\n",
        "Once you’ve fit several regression models, you can compare the AIC value of each model. The model with the lowest AIC offers the best fit.\n",
        "\n",
        "There is no value for AIC that can be considered “good” or “bad” because we simply use AIC as a way to compare regression models. The model with the lowest AIC offers the best fit. The absolute value of the AIC value is not important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyFAfAsYPvL5"
      },
      "outputs": [],
      "source": [
        "## evaluate the model\n",
        "print(model_arima_fit.aic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W5T8tZiPvL6"
      },
      "outputs": [],
      "source": [
        "# forecast() - forecasts data at a specific future point in time\n",
        "# predict() - refers to future data in general\n",
        "forecasting_9 = model_arima_fit.forecast(steps=9) # forecasting for next 9 months"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d26WGD_rPvL7"
      },
      "outputs": [],
      "source": [
        "forecasting_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCCln9fbGcLT"
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhI16YGyPvL9"
      },
      "outputs": [],
      "source": [
        "## plotting the forecasted values\n",
        "plt.plot(forecasting_9,color='green')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXjc4bN1PvL-"
      },
      "outputs": [],
      "source": [
        "## Geeting the optimal values of p,q an d\n",
        "import itertools\n",
        "\n",
        "p =d= q=range(0,4) #values of p,d,q (range can be from 0 to 5 for large datasets)\n",
        "\n",
        "pdq = list(itertools.product(p,d,q))# is used to find the cartesian product from the given iterator,\n",
        "#pdq                     #list of all possible combinations of p,d,q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNuLjFQQGcLV"
      },
      "outputs": [],
      "source": [
        "pdq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaeQgIacPvL_"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "##The Python try… except statement catches an exception. It is used to test code for an error which is written in the “try” statement.\n",
        "#If an error is encountered, the contents of the “except” block are run.\n",
        "aic = []\n",
        "for params in pdq:#iterating params over pdq\n",
        "    try:\n",
        "        model_arima = ARIMA(train, order=params)#training model on various pdq values\n",
        "        model_arima_fit = model_arima.fit()#training\n",
        "        print(params, model_arima_fit.aic)#printing parameter and aic values\n",
        "        aic.append(model_arima_fit.aic)\n",
        "\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2hTtAb5GcLW"
      },
      "outputs": [],
      "source": [
        "min(aic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PL5xhE-PvMA"
      },
      "outputs": [],
      "source": [
        "## create the final model with lowest aic score parameter\n",
        "model_arima = ARIMA(train, order=(3,1,3))\n",
        "\n",
        "model_arima_fit = model_arima.fit()#training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPTFDovJPvMD"
      },
      "outputs": [],
      "source": [
        "forecast = model_arima_fit.forecast(steps=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Wm8UbeGcLY"
      },
      "outputs": [],
      "source": [
        "forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwF_SSXnGcLZ"
      },
      "outputs": [],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjOdDXopPvMF"
      },
      "outputs": [],
      "source": [
        "plt.plot(test,color='red')\n",
        "\n",
        "plt.plot(forecast,color='green')#line plot for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb6q-_g2GcLa"
      },
      "outputs": [],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsaaBKuvGcLa"
      },
      "outputs": [],
      "source": [
        "forecast.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRbtWbBLGcLb"
      },
      "outputs": [],
      "source": [
        "test1 = test[0:42].values.flatten() # convert test to 1D\n",
        "test1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYi_bgupGcLc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tools.eval_measures import rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXUAomPkGcLd"
      },
      "outputs": [],
      "source": [
        "# Calculate root mean squared error\n",
        "print(rmse(test1, forecast))\n",
        "\n",
        "# Calculate mean squared error\n",
        "mean_squared_error(test1, forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWGs77ezGcLd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UsFVvKzGcLf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}